{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yXFmEOnTH1lh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1209e02-9521-4355-d2ed-dca0b7e3352f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycm livelossplot\n",
        "from livelossplot import PlotLosses\n",
        "#import os\n",
        "#os.environ['CUDA_VISIBLE_DEVICES'] ='0'\n",
        "import torch  # Pytorch\n",
        "import torch.nn as nn  # Neural network module\n",
        "import torch.nn.functional as fn  # Function module\n",
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset,Subset\n",
        "from torchvision import datasets  # Datasets from torchvision\n",
        "from torchvision import transforms  # Transforms from torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt  # Plotting using matplotlib\n",
        "import numpy as np  # Numpy\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "from os import listdir\n",
        "\n",
        "device = 'cuda'  # Set out device to GPU\n",
        "\n",
        "print('done')  # Let me know this cell has finished"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOaCE41EIPBF",
        "outputId": "6d8fcfae-6bfc-484c-f2e1-8c1797ee1e87"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pycm\n",
            "  Downloading pycm-3.8-py2.py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.1/66.1 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting livelossplot\n",
            "  Downloading livelossplot-0.5.5-py3-none-any.whl (22 kB)\n",
            "Collecting art>=1.8\n",
            "  Downloading art-5.8-py2.py3-none-any.whl (595 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m595.7/595.7 KB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from pycm) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from livelossplot) (3.2.2)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.8/dist-packages (from livelossplot) (2.3.3)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (6.0.4)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (6.0)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (2.11.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (4.4.0)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.8/dist-packages (from bokeh->livelossplot) (21.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->livelossplot) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->livelossplot) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->livelossplot) (1.4.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (2.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->bokeh->livelossplot) (1.15.0)\n",
            "Installing collected packages: art, pycm, livelossplot\n",
            "Successfully installed art-5.8 livelossplot-0.5.5 pycm-3.8\n",
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = True  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = True\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "def set_device(device=\"cpu\", idx=0):\n",
        "    if device != \"cpu\":\n",
        "        if torch.cuda.device_count() > idx and torch.cuda.is_available():\n",
        "            print(\"Cuda installed! Running on GPU {} {}!\".format(idx, torch.cuda.get_device_name(idx)))\n",
        "            device=\"cuda:{}\".format(idx)\n",
        "        elif torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "            print(\"Cuda installed but only {} GPU(s) available! Running on GPU 0 {}!\".format(torch.cuda.device_count(), torch.cuda.get_device_name()))\n",
        "            device=\"cuda:0\"\n",
        "        else:\n",
        "            device=\"cpu\"\n",
        "            print(\"No GPU available! Running on CPU\")\n",
        "    return device\n",
        "\n",
        "device = set_device(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN-QX2ajImVO",
        "outputId": "d6c23a69-187d-4a28-d057-b64e4f3586d1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available! Running on CPU\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#creating dataset\n",
        "images_path = \"drive/MyDrive/Mars_GAN/images\"\n",
        "labels_path = \"drive/MyDrive/Mars_GAN/labels\"\n",
        "\n",
        "image_list = []\n",
        "label_list = []\n",
        "\n",
        "for labelname in os.listdir(labels_path):\n",
        "  label = pd.read_csv(os.path.join(labels_path, labelname), sep=' ', header=None, index_col = None)\n",
        "  label = np.asarray(label)\n",
        "  label = label[:,1:] #this line should be omitted if the data only contains 4 columns\n",
        "  \n",
        "  if label.shape[0]<5:\n",
        "    zeros = np.zeros((5-label.shape[0],4))\n",
        "    label = np.concatenate([label, zeros], axis=0)\n",
        "  \n",
        "  if label.shape[0]>5:\n",
        "    label = label[0:5,:]\n",
        "  label_list.append(label)\n",
        "  #print(len(label_list))\n",
        "\n",
        "\n",
        "for imgname in os.listdir(images_path):\n",
        "  image = Image.open(os.path.join(images_path, imgname))\n",
        "  data = np.asarray(image)\n",
        "  #print(data.shape)\n",
        "  image_list.append(data)\n",
        "  #image_list = np.array(image_list)\n",
        " # print(image_list)\n",
        "\n",
        "\n",
        "\n",
        "tensor_image = torch.Tensor(image_list)\n",
        "#print(tensor_image.shape) # transform to torch tensor\n",
        "tensor_label = torch.Tensor(label_list)\n",
        "print(tensor_label)\n",
        "\n",
        "my_dataset = TensorDataset(tensor_image, tensor_label) # create your datset\n",
        "my_dataloader = DataLoader(my_dataset) # create your dataloader\n",
        "\n",
        "#my_dataset_label = TensorDataset(tensor_label) # create your datset\n",
        "#my_dataloader_label = DataLoader(my_dataset_label)\n",
        "#print(len(my_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDqXMSQhWpam",
        "outputId": "63fe1fe7-fa94-4d16-934a-a43735a3764b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.8930, 0.8738, 0.1322, 0.1322],\n",
            "         [0.8522, 0.6755, 0.1178, 0.1202],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "        [[0.8438, 0.5036, 0.0577, 0.0601],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "        [[0.2500, 0.9014, 0.1154, 0.1154],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.1058, 0.4363, 0.1298, 0.1322],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "        [[0.1142, 0.7776, 0.1659, 0.1659],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000]],\n",
            "\n",
            "        [[0.9243, 0.2031, 0.0986, 0.0986],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000, 0.0000]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('drive/MyDrive/Mars_GAN/labels/aeolis_43_5.txt', sep=' ', header=None, index_col = None )\n",
        "df = np.asarray(df)\n",
        "print(df)\n",
        "df = df[:,1:]\n",
        "\n",
        "if df.shape[0]<5:\n",
        "  zeros = np.zeros((5-df.shape[0],4))\n",
        "  df = np.concatenate([df, zeros], axis=0)\n",
        "print(df)\n",
        "\n",
        "zeros = np.zeros((7-df.shape[0],4))\n",
        "df = np.concatenate([df, zeros], axis=0)\n",
        "print(df)\n",
        "\n",
        "if df.shape[0]>5:\n",
        "  df = df[0:5,:]\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJObRKK4drWv",
        "outputId": "a76f880a-15f7-441e-85a6-2c532e6e4af8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.89302885 0.87379808 0.13221154 0.13221154]\n",
            " [0.         0.85216346 0.67548077 0.11778846 0.12019231]]\n",
            "[[0.89302885 0.87379808 0.13221154 0.13221154]\n",
            " [0.85216346 0.67548077 0.11778846 0.12019231]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]]\n",
            "[[0.89302885 0.87379808 0.13221154 0.13221154]\n",
            " [0.85216346 0.67548077 0.11778846 0.12019231]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]]\n",
            "[[0.89302885 0.87379808 0.13221154 0.13221154]\n",
            " [0.85216346 0.67548077 0.11778846 0.12019231]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]\n",
            " [0.         0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, g_input_dim=100, g_output_dim=416*416+20):\n",
        "        super().__init__()       \n",
        "        self.fc1 = nn.Linear(g_input_dim, 256)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n",
        "    \n",
        "    # forward method\n",
        "    def forward(self, x, c): \n",
        "        x = torch.flatten(x)\n",
        "        c = torch.flatten(c)\n",
        "        print(x.shape)\n",
        "        print(c.shape)\n",
        "        x = torch.cat([x, c], dim=-1)\n",
        "        print(x.shape)\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        return torch.tanh(self.fc4(x))\n",
        "    \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, d_input_dim=416*416+20):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(d_input_dim, 1024)\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, 1) #input size\n",
        "    \n",
        "    # forward method\n",
        "    def forward(self, x, c):\n",
        "        x = torch.flatten(x)\n",
        "        c = torch.flatten(c)\n",
        "        print(x.shape)\n",
        "        print(c.shape)\n",
        "        x = torch.cat([x, c], dim=-1)\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        #x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        #x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        #x = F.dropout(x, 0.3)\n",
        "        return torch.sigmoid(self.fc4(x))\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)"
      ],
      "metadata": {
        "id": "w5OCCW8eIrhy"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define loss\n",
        "criterion = nn.BCELoss() \n",
        "z_dim = 100\n",
        "bs = 1  ## batch_size\n",
        "\n",
        "\n",
        "# optimiser\n",
        "lr = 0.0001 \n",
        "G_optimizer = torch.optim.Adam(G.parameters(), lr = lr)\n",
        "D_optimizer = torch.optim.Adam(D.parameters(), lr = lr)"
      ],
      "metadata": {
        "id": "IQd0hrahKU9E"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyVZf-tJ3mAv",
        "outputId": "8d1f1e19-6b4b-4365-a162-532bdddc1b8b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (fc1): Linear(in_features=100, out_features=256, bias=True)\n",
              "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
              "  (fc3): Linear(in_features=512, out_features=1024, bias=True)\n",
              "  (fc4): Linear(in_features=1024, out_features=173076, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEcXP9hN3oCu",
        "outputId": "99fddb58-a055-458a-de47-9c145b5b3cfa"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (fc1): Linear(in_features=173076, out_features=1024, bias=True)\n",
              "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
              "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (fc4): Linear(in_features=256, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def D_train(x,c):\n",
        "    #-------------- Function of the discriminator training -------------------#\n",
        "    D.train()\n",
        "    D_optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    # train discriminator on real data -- assign high score (use 1 here)\n",
        "    x_real, y_real = x.view(-1, 416**2), torch.ones(bs, 1)  # we are assigning the label 'real data' to the samples (don't care anymore about what number they are)\n",
        "    x_real, y_real = x_real.to(device), y_real.to(device)\n",
        "\n",
        "\n",
        "    D_output = D(x_real, c.to(device)) ##remember this!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "    #D_output = D(x_real)\n",
        "   # D_output = D_output.view(1, 1)\n",
        "    D_real_loss = criterion(D_output.to(device), y_real)\n",
        "\n",
        "    # train discriminator on fake data -- assign low score (use 0 here)\n",
        "    # sample vector and produce generator output\n",
        "    z = torch.randn(bs, z_dim).to(device)\n",
        "    x_fake, y_fake = G(z, c.to(device)), torch.zeros(bs, 1).to(device)\n",
        "\n",
        "    \n",
        "    D_output = D(x_fake.to(device), c.to(device)) ##remember this!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "    #D_output = D(x_fake.to(device))\n",
        "    D_fake_loss = criterion(D_output, y_fake)\n",
        "\n",
        "    # combine the losses\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "\n",
        "    # model update \n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "        \n",
        "    return  D_loss.data.item()  ### deprecated version of loss.detach(), basically gets access to the tensor without the computational graph attached"
      ],
      "metadata": {
        "id": "Ee2-NmocKb7f"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def G_train(x,c):\n",
        "    #-------------- Function of the generator training -------------------#\n",
        "    G.train()\n",
        "    G_optimizer.zero_grad()\n",
        "\n",
        "    # sample vector and produce generator output\n",
        "    z = torch.randn(bs, z_dim).to(device)\n",
        "    G_output = G(z, c.to(device))\n",
        "\n",
        "    # obtain scores from D for the generated data\n",
        "    D_output = D(G_output, c.to(device))\n",
        "\n",
        "    # train generator to \"fool\" discriminator\n",
        "    y = torch.ones(bs, 1).to(device)\n",
        "    G_loss = criterion(D_output, y)\n",
        "\n",
        "    # model update \n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "        \n",
        "    return G_loss.data.item()  ### deprecated version of loss.detach(), basically gets access to the tensor without the computational graph attached\n",
        "     "
      ],
      "metadata": {
        "id": "uqJ4ExuwKgHl"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for a, (i,j) in enumerate(my_dataloader):\n",
        "  print(a)\n",
        "  print(i.shape)\n",
        "  print(j.shape)\n",
        "  i = torch.flatten(i)\n",
        "  j = torch.flatten(j)\n",
        "  print(i.shape)\n",
        "  print(j.shape)\n",
        "  #new = torch.cat([i, j], dim=)\n",
        "  #torch.set_printoptions(profile=\"full\")\n",
        "  #print(new)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcYQems3_UBX",
        "outputId": "c59a7963-c532-4fe1-8ddb-c1a9e4eef1c1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "torch.Size([1, 416, 416])\n",
            "torch.Size([1, 5, 4])\n",
            "torch.Size([173056])\n",
            "torch.Size([20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "n_epoch = 200 # about 40 minutes\n",
        "groups = {'Loss': ['D_Loss', 'G_Loss']}\n",
        "liveloss = PlotLosses(groups=groups)\n",
        "\n",
        "for epoch in range(1, n_epoch+1):  \n",
        "  D_losses, G_losses = [], []\n",
        "  logs = {}\n",
        "\n",
        "  for batch_idx, (img, labels) in enumerate(my_dataloader):\n",
        "    logs['D_Loss'] = D_train(img, labels)\n",
        "    logs['G_Loss'] = G_train(img, labels)\n",
        "      \n",
        "  liveloss.update(logs)\n",
        "  liveloss.draw()\n",
        "\n",
        "  # save every 20th epochs \n",
        "  if(np.mod(epoch, 20) == 0):\n",
        "    torch.save(G.state_dict(), \"./Generator_{:03d}.pth\".format(epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "ksj_CSfnKg9-",
        "outputId": "870fcc5e-b932-453c-cf9c-ed993b6521d4"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([173056])\n",
            "torch.Size([20])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-b63cfce2dc29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'D_Loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mlogs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'G_Loss'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-86-d556885324f5>\u001b[0m in \u001b[0;36mD_train\u001b[0;34m(x, c)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#D_output = D(x_real)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m    \u001b[0;31m# D_output = D_output.view(1, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mD_real_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# train discriminator on fake data -- assign low score (use 0 here)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0mreduction_enum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3085\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3086\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   3087\u001b[0m             \u001b[0;34m\"Using a target size ({}) that is different to the input size ({}) is deprecated. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3088\u001b[0m             \u001b[0;34m\"Please ensure they have the same size.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1])) is deprecated. Please ensure they have the same size."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yx1usBGlKnVy"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}